{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第５章　誤差逆伝搬法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第4章では数値微分と勾配法を使って、ニューラルネットワークの学習が可能であることを示しました。実際の学習では計算時間および計算精度の観点から数値微分は使われずに、ニューラルネットワークの解析的微分を効率よく計算するためのアルゴリズムである誤差逆伝搬法が使われます。この章では誤差逆伝搬法を学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単純な関数の解析的微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純な関数の微分は解析的な表現が知られていることが多いです。\n",
    "\n",
    "$$\n",
    "f(x) = x^n \\Rightarrow \\frac{df}{dx} = nx^{n-1} \\\\\n",
    "f(x) = \\sin(ax) \\Rightarrow \\frac{df}{dx} = a\\cos(ax) \\\\\n",
    "f(x) = \\cos(ax) \\Rightarrow \\frac{df}{dx} = -a\\sin(ax) \\\\\n",
    "f(x) = \\exp(ax) \\Rightarrow \\frac{df}{dx} = a\\exp(ax)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合成関数の微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、複雑な関数の微分はどのように計算するのでしょうか。ここで二つの関数\n",
    "$$\n",
    "y = f(x) \\\\\n",
    "z = g(y)\n",
    "$$\n",
    "が与えられていると、その合成関数$g\\circ f$を考えます。\n",
    "$$\n",
    "(g\\circ f)(x) = g(f(x))\n",
    "$$\n",
    "\n",
    "多くの複雑な関数は単純な関数の合成で表現することができることに注意してください。\n",
    "実は、合成関数$g\\circ f$の微分は次のように、部品となった関数$f, g$の微分で表現することができます。\n",
    "\n",
    "$$\n",
    "    \\frac{dz}{dx} = \\frac{dz}{dy} \\frac{dy}{dx}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数が複数ある場合は偏微分を使った次のような拡張が必要になります。例えば次のような関数を考えます。\n",
    "$$\n",
    "y_1 = f_1(x_1, x_2) \\\\\n",
    "y_2 = f_2(x_1, x_2) \\\\\n",
    "z = g(y_1, y_2)\n",
    "$$\n",
    "ここで、偏微分は次のように計算できることが知られています。\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x_1} = \\frac{\\partial z}{\\partial y_1}\\frac{\\partial y_1}{\\partial x_1} + \\frac{\\partial z}{\\partial y_2}\\frac{\\partial y_2}{\\partial x_1}\n",
    "$$\n",
    "一般化して、ベクトルで表現すると、\n",
    "$$\n",
    "    {\\bf y} = {\\bf f}({\\bf x}) \\\\\n",
    "    z = g({\\bf y})\n",
    "$$\n",
    "に対して、\n",
    "$$\n",
    "    \\frac{\\partial z}{\\partial x_1} = \\frac{\\partial z}{\\partial {\\bf y}} \\cdot \\frac{\\partial {\\bf y}}{\\partial x_1}\n",
    "$$\n",
    "と表現される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークは行列積と活性化層による非線形変換の組み合わせで表現されます。例えばニューラルネットワークの単一層は次のように表現されます。\n",
    "$$\n",
    "    {\\bf a} = {\\bf W}{\\bf x} + {\\bf B} \\\\\n",
    "    {\\bf z} = {\\bf h}({\\bf a})\n",
    "$$\n",
    "出力${\\bf z}$の重みに対する微分は次のように表現できます。\n",
    "$$\n",
    "    \\frac{\\partial {\\bf z}}{\\partial{\\bf W}} \n",
    "    = \\frac{\\partial {\\bf z}}{\\partial{\\bf a}}\\cdot \\frac{\\partial {\\bf a}}{\\partial{\\bf W}} \\\\\n",
    "    = {\\bf h}'({\\bf a})\\cdot {\\bf x}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
